DEBUG:asyncio:Using proactor: IocpProactor
INFO:uvicorn.error:Started server process [29428]
INFO:uvicorn.error:Waiting for application startup.
INFO:pythonConfig:GPU available: True
INFO:pythonConfig:<torch.cuda.device object at 0x000002354F64D940>
INFO:uvicorn.error:Application startup complete.
INFO:uvicorn.error:Uvicorn running on http://localhost:8005 (Press CTRL+C to quit)
INFO:pythonConfig:The model is: ../models/HRNet.pkl
INFO:pythonConfig:Model ../models/HRNet.pkl loaded successfully
INFO:pythonConfig:Images will imported from: C:\Users\hatho\OneDrive\CASA\BEAM_RAW_Files-main\test-image\testset
INFO:pythonConfig:Input Images are:
C:\Users\hatho\OneDrive\CASA\BEAM_RAW_Files-main\test-image\testset\2020_RGB_10cm_CA_065.tif
INFO:pythonConfig:The model is: C:\Users\hatho\OneDrive\CASA\BEAM_RAW_Files-main\models\RAMP_all_30_epochs_exported.pkl
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\uvicorn\protocols\http\h11_impl.py", line 366, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\uvicorn\middleware\proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\fastapi\applications.py", line 261, in __call__
    await super().__call__(scope, receive, send)
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\starlette\applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\starlette\middleware\errors.py", line 181, in __call__
    raise exc
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\starlette\middleware\errors.py", line 159, in __call__
    await self.app(scope, receive, _send)
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\starlette\middleware\cors.py", line 92, in __call__
    await self.simple_response(scope, receive, send, request_headers=headers)
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\starlette\middleware\cors.py", line 147, in simple_response
    await self.app(scope, receive, send)
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\starlette\exceptions.py", line 82, in __call__
    raise exc
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\starlette\exceptions.py", line 71, in __call__
    await self.app(scope, receive, sender)
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\fastapi\middleware\asyncexitstack.py", line 21, in __call__
    raise e
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\fastapi\middleware\asyncexitstack.py", line 18, in __call__
    await self.app(scope, receive, send)
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\starlette\routing.py", line 656, in __call__
    await route.handle(scope, receive, send)
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\starlette\routing.py", line 259, in handle
    await self.app(scope, receive, send)
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\starlette\routing.py", line 61, in app
    response = await func(request)
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\fastapi\routing.py", line 227, in app
    raw_response = await run_endpoint_function(
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\fastapi\routing.py", line 162, in run_endpoint_function
    return await run_in_threadpool(dependant.call, **values)
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\starlette\concurrency.py", line 39, in run_in_threadpool
    return await anyio.to_thread.run_sync(func, *args)
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\anyio\to_thread.py", line 28, in run_sync
    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\anyio\_backends\_asyncio.py", line 818, in run_sync_in_worker_thread
    return await future
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\anyio\_backends\_asyncio.py", line 754, in run
    result = context.run(func, *args)
  File "C:\Users\hatho\OneDrive\CASA\BEAM_RAW_Files-main\unitac-backend\main.py", line 127, in load_model
    loaded_model = load_learner(
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\fastai\learner.py", line 384, in load_learner
    res = torch.load(fname, map_location='cpu' if cpu else None, pickle_module=pickle_module)
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\serialization.py", line 607, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\serialization.py", line 882, in _load
    result = unpickler.load()
  File "C:\Users\hatho\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\serialization.py", line 875, in find_class
    return super().find_class(mod_name, name)
AttributeError: Can't get attribute 'CastToTensor' on <module 'fastai.learner' from 'C:\\Users\\hatho\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\fastai\\learner.py'>
