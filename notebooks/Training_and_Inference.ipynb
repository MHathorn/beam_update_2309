{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq9dWBcYaaPU"
      },
      "source": [
        "# BEAM Training and Inference Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook provides a pipeline for training the models used in the Building and Establishment Automated Mapper (BEAM) tool. It describes the inputs to the training functions, and the pipeline to generate predictions from trained models. This workflow was designed to work with 10cm aerial imagery from eThekwini Municipality. The Tiling_Notebook should be run first for image preprocessing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_qhiRIyakGF"
      },
      "source": [
        "## 1. Imports and set paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPm_LSaC7FmC"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "from fastai.vision.all import *\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import pytz\n",
        "from datetime import datetime\n",
        "from semtorch import get_segmentation_learner\n",
        "from IPython.display import Audio, display\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from natsort import os_sorted\n",
        "from os.path import join, exists\n",
        "from os import listdir, makedirs, remove, stat\n",
        "import glob\n",
        "\n",
        "import rasterio\n",
        "import rasterio.features\n",
        "from rasterio.features import rasterize\n",
        "import rasterio.plot\n",
        "import sys\n",
        "import cv2\n",
        "\n",
        "import shapely.geometry\n",
        "from shapely.geometry import MultiPolygon, Polygon\n",
        "from shapely.ops import unary_union\n",
        "import geopandas as gpd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuVI1Igby35I"
      },
      "source": [
        "Uncomment and run this next cell if running on Google Colab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usvkzH_S_SoO",
        "outputId": "cf5d2d62-56ae-4786-db47-44df99630c7c"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# # Mount Google Drive\n",
        "# drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Update the path in this next code chunk to the root folder with your training images (should be the same as the root folder used in the tiling notebook).\n",
        "\n",
        "Also define the path where you want models to be saved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set path of root folder that contains all required data\n",
        "path = Path(f'your_path')\n",
        "\n",
        "# Set codes (classes contained in masks)\n",
        "codes = ['Background', 'Building']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run this cell to confirm GPU access -- should return True:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HMbvM6HasEz"
      },
      "source": [
        "## 2. Define Required Functions and Set Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL0eFyoBbJTJ"
      },
      "source": [
        "### 2.1. Loss Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These are custom loss functions that can be used with the different models. However, the fastai default loss function for semantic segmentation (flattened cross-entropy) is recommended. The Dice Focal combined loss below produces inferior results in training, and the Dual Focal loss produces an output with two colour channels, making it difficult to use for generating predictions. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-15slAsa_kc"
      },
      "outputs": [],
      "source": [
        "# Create custom loss functions for later experiments\n",
        "class CombinedLoss:\n",
        "    \"\"\"Dice and Focal combined\"\"\"\n",
        "    def __init__(self, axis=1, smooth=1., alpha=1.):\n",
        "        store_attr()\n",
        "        self.focal_loss = FocalLossFlat(axis=axis)\n",
        "        self.dice_loss =  DiceLoss(axis, smooth)\n",
        "        \n",
        "    def __call__(self, pred, targ):\n",
        "        return self.focal_loss(pred, targ) + self.alpha * self.dice_loss(pred, targ)\n",
        "    \n",
        "    def decodes(self, x):    return x.argmax(dim=self.axis)\n",
        "    def activation(self, x): return F.softmax(x, dim=self.axis)\n",
        "\n",
        "\n",
        "class Dual_Focal_loss(nn.Module):\n",
        "    \"\"\"This loss is proposed in this paper: https://arxiv.org/abs/1909.11932\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ignore_lb=255, eps=1e-5, reduction='mean'):\n",
        "        super(Dual_Focal_loss, self).__init__()\n",
        "        self.ignore_lb = ignore_lb\n",
        "        self.eps = eps\n",
        "        self.reduction = reduction\n",
        "        self.mse = nn.MSELoss(reduction='none')\n",
        "\n",
        "    def forward(self, logits, label):\n",
        "        ignore = label.data.cpu() == self.ignore_lb\n",
        "        n_valid = (ignore == 0).sum()\n",
        "        label = label.clone()\n",
        "        label[ignore] = 0\n",
        "        lb_one_hot = logits.data.clone().zero_().scatter_(1, label.unsqueeze(1), 1).detach()\n",
        "\n",
        "        pred = torch.softmax(logits, dim=1)\n",
        "        loss = -torch.log(self.eps + 1. - self.mse(pred, lb_one_hot)).sum(dim=1)\n",
        "        loss[ignore] = 0\n",
        "        if self.reduction == 'mean':\n",
        "            loss = loss.sum() / n_valid\n",
        "        elif self.reduction == 'sum':\n",
        "            loss = loss.sum()\n",
        "        elif self.reduction == 'none':\n",
        "            loss = loss\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sazgAjK7WuQT"
      },
      "source": [
        "### Define Required Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These are helper functions that are used in the training functions that follow. They perform tasks that include gathering codes from a list of filenames, adjusting pixels in a mask, setting the batch size, creating missing folders, generating timestamps, creating notifications, and checking the balance of the dataset. The subsequent functions that follow in the code use these helper functions to define the arguments in the main training functions, which help to set the model hyperparameters for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhqX3kaLFtfY",
        "outputId": "ccede33c-9ad2-49c2-e7db-ba1e983f2874"
      },
      "outputs": [],
      "source": [
        "\n",
        "def n_codes(fnames, is_partial = True):\n",
        "  \"\"\"Gather the codes (classes contained in masks) from a list of `fnames`\"\"\"\n",
        "  vals = set() # create an empty set to store unique values\n",
        "  if is_partial:\n",
        "    random.shuffle(fnames) # shuffle the list of filenames\n",
        "    fnames = fnames[:10] # select the first 10 filenames\n",
        "  for fname in fnames:\n",
        "    msk = np.array(PILMask.create(fname)) # create a numpy array from the mask image\n",
        "    for val in np.unique(msk): # loop through the unique values in the mask\n",
        "      if val not in vals: # if the value is not already in the set of unique values\n",
        "        vals.add(val) # add it to the set\n",
        "  vals = list(vals) # convert the set back to a list\n",
        "  p2c = dict() # create an empty dictionary to store the pixel-to-class mapping\n",
        "  for i,val in enumerate(vals):\n",
        "    p2c[i] = vals[i] # assign each unique value to a key in the dictionary\n",
        "  return p2c\n",
        "\n",
        "def get_msk(fn, p2c):\n",
        "  \"\"\"Grab a mask from a `filename` and adjust the pixels based on `p2c`\"\"\"\n",
        "  path = Path('your_path') # set the path to the image and mask folders\n",
        "  pix2class = n_codes(lbl_names) # get the pixel-to-class mapping\n",
        "  fn = str(fn).replace('image_tiles', 'mask_tiles') # replace the image folder name with the mask folder name in the filename\n",
        "  msk = np.array(PILMask.create(fn)) # create a numpy array from the mask image\n",
        "  mx = np.max(msk) # get the maximum value in the mask\n",
        "  for i, val in enumerate(p2c): # loop through the pixel-to-class mapping\n",
        "    msk[msk==p2c[i]] = val # replace each pixel value in the mask with its corresponding class value\n",
        "  return PILMask.create(msk) # create a PIL image from the adjusted mask\n",
        "\n",
        "def get_y(o):\n",
        "  return get_msk(o, p2c) # return the adjusted mask for a given filename\n",
        "\n",
        "def batch_size(backbone, tile_size):\n",
        "  \"\"\"Automatically set batch size depending on image size and architecture used\"\"\"\n",
        "  if '512' in tile_size:\n",
        "    batch_size_dict = {'resnet152': 2, 'resnet101': 2, 'resnet50': 2,\n",
        "                       'resnet34': 11, 'resnet18': 10, 'vgg16_bn': 2,\n",
        "                       'hrnet_w18': 32, 'hrnet_w30': 32, 'hrnet_w32': 32,\n",
        "                       'hrnet_w48': 18} # set batch sizes for different architectures and image sizes\n",
        "  elif '256' in tile_size:\n",
        "    batch_size_dict = {'resnet152': 2, 'resnet101': 2, 'resnet50': 2,\n",
        "                       'resnet34': 11, 'resnet18': 10, 'hrnet_w18': 64} # set batch sizes for different architectures and image sizes\n",
        "  return batch_size_dict[backbone] # return the batch size for a given architecture and image size\n",
        "\n",
        "def create_missing_folder(folder):\n",
        "  \"\"\"Create missing folders\"\"\"\n",
        "  if not os.path.exists(folder): # if the folder does not exist\n",
        "    os.makedirs(folder) # create it\n",
        "\n",
        "def timestamp():\n",
        "  \"\"\"Timestamp experiments\"\"\"\n",
        "  tz = pytz.timezone('Europe/Berlin') # set the timezone\n",
        "  date = str(datetime.now(tz)).split(\" \") # get the current date and time in the specified timezone\n",
        "  date_time = f\"{date[0]}_{date[1].split('.')[0][:5]}\" # format the date and time\n",
        "  return date_time\n",
        "\n",
        "def model_notification():\n",
        "  \"\"\"Create notification when model training is completed\"\"\"\n",
        "  for i in range(5):\n",
        "    display(Audio('https://www.soundjay.com/buttons/beep-03.wav', autoplay = True)) # play a sound\n",
        "    time.sleep(2) # wait for 2 seconds\n",
        "\n",
        "def get_tile_size(tile_type):\n",
        "  \"\"\"Set 'tile_size' variable based on the name of the tile folder\"\"\"\n",
        "  if '512' in tile_type:\n",
        "    tile_size = '512' # set the tile size to 512\n",
        "  elif '256' in tile_type:\n",
        "    tile_size = '256' # set the tile size to 256\n",
        "  return tile_size\n",
        "\n",
        "def check_fnames_lbls(tile_type):\n",
        "  \"\"\"Get images and labels for dataloader and check whether their number is equal\"\"\"\n",
        "  global fnames, lbl_names, path # make the variables global so they can be accessed outside the function\n",
        "  fnames = get_image_files(f'{path}/image_tiles/2019_10cm_RGB_BE_67/{tile_type}') # get the filenames of the image tiles\n",
        "  lbl_names = get_image_files(f'{path}/buildings_mask_tiles/2019_10cm_RGB_BE_67/{tile_type}') # get the filenames of the mask tiles\n",
        "  if len(fnames) != len(lbl_names): # if the number of image tiles is not equal to the number of mask tiles\n",
        "    print('ERROR: unequal number of image and mask tiles!') # print an error message\n",
        "  return fnames, lbl_names, path\n",
        "\n",
        "def callbacks(model_dir, architecture, backbone, fit_type, timestamp):\n",
        "  \"\"\"Log results in CSV, show progress\"\"\"\n",
        "  cbs = [CSVLogger(fname = f'{model_dir}/{architecture}_{backbone}_{fit_type}_{timestamp()}.csv', append = True), # log results in a CSV file\n",
        "        ShowGraphCallback()] # \n",
        "  return cbs\n",
        "\n",
        "def check_dataset_balance(tile_type):\n",
        "  \"\"\"Check balance of the dataset\"\"\"\n",
        "  global tile_size, p2c # make the variables global so they can be accessed outside the function\n",
        "  tile_size = get_tile_size(tile_type) # get the tile size\n",
        "  # Check if there is a label for each image\n",
        "  fnames, lbl_names, path = check_fnames_lbls(tile_type) # get the filenames of the image and mask tiles\n",
        "\n",
        "  # Get codes of masks\n",
        "  p2c = n_codes(lbl_names) # get the pixel-to-class mapping\n",
        "\n",
        "  label_func = get_y\n",
        "\n",
        "  # Create dataloader to check building pixels\n",
        "  dls = SegmentationDataLoaders.from_label_func(path, fnames, label_func = label_func, bs = 64, codes = codes, seed = 2) # create a dataloader\n",
        "\n",
        "  targs = torch.zeros((0, 512, 512)) # create a tensor to store the mask pixels\n",
        "  for _, masks in dls[0]:\n",
        "    targs = torch.cat((targs, masks.cpu()), dim = 0) # concatenate the mask pixels\n",
        "\n",
        "  total_pixels = targs.shape[1]**2 # calculate the total number of pixels\n",
        "  percentages = torch.count_nonzero(targs, dim = (1,2)) / total_pixels # calculate the percentage of pixels that belong to the building class\n",
        "  plt.hist(percentages, bins = 20) # plot a histogram of the percentages\n",
        "  plt.ylabel('Number of tiles')\n",
        "  plt.xlabel('Ratio of pixels that are of class `building`')\n",
        "  plt.gca().spines['top'].set_color('none')\n",
        "  plt.gca().spines['right'].set_color('none')\n",
        "  plt.show()\n",
        "  print(f'Mean Percentage of Pixels Belonging to Buildings: {round(percentages.mean().item(), 3)}') # print the mean percentage of pixels that belong to the building class\n",
        "  return percentages # return the percentages\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These are the main training functions for the BEAM models. The functions work similarly, with the `u_net_model_training` function using a list of files and masks, a dataloader, a model, and callbacks to train a final U-Net model. It takes several arguments, including the tile type, backbone, loss function, fit type, and number of epochs. It uses the helper functions defined earlier to define these arguments and hyperparameters. It also creates image augmentations on the fly and sets the loss function based on the user's input.\n",
        "\n",
        "The `hrnet_model_training` function is similar to `u_net_model_training`, but it uses the HRNet architecture instead of the U-Net architecture. \n",
        "\n",
        "The `test_inference` function tests the inference speed of a model. It takes a dataloader and a trained model as arguments and returns the duration of the inference process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def u_net_model_training(tile_type, backbone, loss_function, fit_type, epochs, architecture = 'U-Net', split = .2):\n",
        "  \"\"\"Create list of files and masks, a dataloader, a model, callbacks, and trains the final U-Net model\"\"\"\n",
        "  global tile_size, p2c, loss\n",
        "  tile_size = get_tile_size(tile_type)\n",
        "  # Create image augmentations on the fly\n",
        "  tfms = [*aug_transforms(mult=1.0, do_flip=True, flip_vert=True, max_rotate=40.0, min_zoom=1.0, max_zoom=1.4, max_warp=0.4),\n",
        "  Normalize.from_stats(*imagenet_stats),\n",
        "  Brightness(max_lighting=0.5),\n",
        "  Contrast(max_lighting=0.5),\n",
        "  Hue(max_hue=0.2),\n",
        "  Saturation(max_lighting=0.5)]\n",
        "\n",
        "  # Check if there is a label for each image\n",
        "  fnames, lbl_names, path = check_fnames_lbls(tile_type)\n",
        "\n",
        "  # Get codes of masks\n",
        "  p2c = n_codes(lbl_names)\n",
        "\n",
        "  # Automatically set batch size depending on image size and backbone used\n",
        "  bs = batch_size(backbone, tile_size)\n",
        "\n",
        "  # Create dataloader to load images and masks\n",
        "  dls = SegmentationDataLoaders.from_label_func(path, fnames, label_func = get_y, valid_pct = split,\n",
        "                                              bs = bs, codes = codes, seed = 2, batch_tfms = tfms)\n",
        "  \n",
        "  # Show, which loss function is used for the experiment and set the variable accordingly\n",
        "  print('loss_function: ', loss_function)\n",
        "  if loss_function == 'Dual_Focal_loss':\n",
        "    loss = Dual_Focal_loss()\n",
        "  elif loss_function == 'CombinedLoss':\n",
        "    loss = CombinedLoss()\n",
        "  elif loss_function == 'DiceLoss':\n",
        "    loss = DiceLoss()\n",
        "  elif loss_function == 'FocalLoss':\n",
        "    loss = FocalLoss()\n",
        "  if loss_function == None:\n",
        "    loss = None\n",
        "    \n",
        "  # Create U-Net model with the selected backbone\n",
        "  if backbone == 'resnet18':\n",
        "    learn = unet_learner(dls, resnet18, n_out = 2, loss_func = loss, metrics = [Dice(), JaccardCoeff()] # Dice coefficient since dataset is imbalanced\n",
        "                        ).to_fp16() # 16-bits floats, which take half the space in RAM\n",
        "  elif backbone == 'resnet34':\n",
        "    learn = unet_learner(dls, resnet34, n_out = 2, loss_func = loss, metrics = [Dice(), JaccardCoeff()]).to_fp16()\n",
        "  elif backbone == 'resnet50':\n",
        "    learn = unet_learner(dls, resnet50, n_out = 2, loss_func = loss, metrics = [Dice(), JaccardCoeff()]).to_fp16()\n",
        "  elif backbone == 'resnet101':\n",
        "    learn = unet_learner(dls, resnet101, n_out = 2, loss_func = loss, metrics = [Dice(), JaccardCoeff()]).to_fp16()\n",
        "  elif backbone == 'vgg16_bn':\n",
        "    learn = unet_learner(dls, vgg16_bn, n_out = 2, loss_func = loss, metrics = [Dice(), JaccardCoeff()]).to_fp16()\n",
        "\n",
        "  # Fit the model\n",
        "  learn.fit_one_cycle(epochs, cbs = callbacks(model_dir, architecture, backbone, fit_type, timestamp))\n",
        "  return learn, dls\n",
        "\n",
        "def seed():\n",
        "  \"\"\"Creates a seed for experiments to be reproducible\"\"\"\n",
        "  number_of_the_seed = 2022\n",
        "  random.seed(number_of_the_seed)\n",
        "  set_seed(number_of_the_seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def hrnet_model_training(tile_type, backbone, loss_function, fit_type, epochs, architecture = 'HRNet', split = .2, bs = None):\n",
        "  \"\"\"Set a seed, create a list of files and masks, a dataloader, a model, callbacks, and trains the final U-Net model\"\"\"\n",
        "  global tile_size, p2c, loss\n",
        "  seed()\n",
        "\n",
        "  tile_size = get_tile_size(tile_type)\n",
        "\n",
        "  tfms = [*aug_transforms(mult=1.0, do_flip=True, flip_vert=True, max_rotate=40.0, min_zoom=1.0, max_zoom=1.4, max_warp=0.4),\n",
        "  Normalize.from_stats(*imagenet_stats),\n",
        "  Brightness(max_lighting=0.5),\n",
        "  Contrast(max_lighting=0.5),\n",
        "  Hue(max_hue=0.2),\n",
        "  Saturation(max_lighting=0.5)]\n",
        "\n",
        "  fnames, lbl_names, path = check_fnames_lbls(tile_type)\n",
        "\n",
        "  if bs == None:\n",
        "    bs = batch_size(backbone, tile_size)\n",
        "\n",
        "  # Get codes of masks\n",
        "  p2c = n_codes(lbl_names)\n",
        "\n",
        "\n",
        "  # Create function to load images and masks\n",
        "  dls = SegmentationDataLoaders.from_label_func(path, fnames, label_func = get_y, bs = bs, codes = codes, seed = 2022,\n",
        "                                                  batch_tfms = tfms, valid_pct = split)\n",
        "\n",
        "  # Set the variable for the used loss function\n",
        "  if loss_function == 'Dual_Focal_loss':\n",
        "    loss = Dual_Focal_loss()\n",
        "  elif loss_function == 'CombinedLoss':\n",
        "    loss = CombinedLoss()\n",
        "  elif loss_function == 'DiceLoss':\n",
        "    loss = DiceLoss()\n",
        "  elif loss_function == 'FocalLoss':\n",
        "    loss = FocalLoss()\n",
        "  if loss_function == None:\n",
        "    loss = None\n",
        "\n",
        "  # Create HRNet model\n",
        "  learn = get_segmentation_learner(dls, number_classes = 2, segmentation_type = \"Semantic Segmentation\",\n",
        "                                   architecture_name = \"hrnet\", backbone_name = backbone,\n",
        "                                   model_dir = model_dir, metrics = [Dice()], splitter = trainable_params,\n",
        "                                   pretrained = True, loss_func = loss).to_fp16()\n",
        "\n",
        "  # Fit the model\n",
        "  learn.fit_one_cycle(epochs, cbs = callbacks(model_dir, architecture, backbone, fit_type, timestamp))\n",
        "  return learn, dls\n",
        "\n",
        "\n",
        "\n",
        "def test_inference(dls, learn):\n",
        "  \"\"\"Test inference speed of a model\"\"\"\n",
        "  input_dir = '/content/drive/MyDrive/Segmentation Data/aerial/inference/input/2019'\n",
        "  # Time prediction on all tiles\n",
        "  start_time_inf = datetime.now()\n",
        "  preds = learn.get_preds(dl = dls.test_dl(get_image_files(input_dir)))\n",
        "  end_time_inf = datetime.now()\n",
        "  duration = end_time_inf - start_time_inf\n",
        "  return duration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apB6dPL44jyx"
      },
      "source": [
        "## 3. Check Dataset Imbalance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKVJlobKbbp5"
      },
      "source": [
        "### 3.1. Full manually labelled dataset (400 tiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "CkJ5d3Fx0mFL",
        "outputId": "62bfe104-ac2d-4131-e3c3-03b23c8f86be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1051: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  ret = func(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEHCAYAAABBW1qbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbP0lEQVR4nO3deZhcVZ3/8feHhEXWENLyYEJMwKgPuLC0DIgimxJEEh5/oKCjAfKb6E9GUGEEXIAZZ4YwiAqO6C8IQ1SGVQfihiAkoLKGAElYIjGCJAYSRBZRkcB3/rinby5FdfXtrq66Xd2f1/PUk3PX863blfrWuefecxURmJmZAWxQdQBmZjZ0OCmYmVnOScHMzHJOCmZmlnNSMDOz3OiqA2jG1KlT49prr606DDOzTqPeFnR0S+GJJ56oOgQzs2Glo5OCmZkNLicFMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOzXMuSgqSLJK2RtLTOshMlhaRxaVqSzpO0XNJiSbu1Ki4zM+tdK1sKFwNTa2dK2h54D/C7wuyDgSnpNQv4ZgvjMjOzXrQsKUTEzcCTdRZ9FfgsUHyQw3TgO5G5DRgjabtWxWZmZvW1dZgLSdOBVRFxr/Syu6zHA48Wplemeavr7GMWWWuCiRMnDjiWSaf8eMDbAjw8+5CmtjczG4ra1tEsaVPgc8BpzewnIuZERHdEdHd1dQ1OcGZmBrS3pbAjMBnoaSVMABZJ2gNYBWxfWHdCmmdmZm3UtpZCRCyJiFdHxKSImER2imi3iHgMmAd8NF2FtCfwdES84tSRmZm1VisvSb0UuBV4g6SVkmY2WP0nwApgOXAB8IlWxWVmZr1r2emjiDiqj+WTCuUAjmtVLGZmVo7vaDYzs5yTgpmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmOScFMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOznJOCmZnlnBTMzCznpGBmZrmWJQVJF0laI2lpYd7Zkh6UtFjS/0gaU1h2qqTlkpZJOqhVcZmZWe9a2VK4GJhaM+964E0R8Rbg18CpAJJ2Ao4Edk7bnC9pVAtjMzOzOlqWFCLiZuDJmnnXRcS6NHkbMCGVpwOXRcTzEfFbYDmwR6tiMzOz+qrsUzgW+GkqjwceLSxbmea9gqRZkhZKWrh27doWh2hmNrJUkhQkfR5YB1zS320jYk5EdEdEd1dX1+AHZ2Y2go1ud4WSjgbeBxwQEZFmrwK2L6w2Ic0zM7M2amtLQdJU4LPAtIj4c2HRPOBISRtLmgxMAe5oZ2xmZtbCloKkS4F9gXGSVgKnk11ttDFwvSSA2yLi4xFxn6QrgPvJTisdFxEvtio2MzOrr2VJISKOqjP7wgbr/xvwb62Kx8zM+uY7ms3MLOekYGZmOScFMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOznJOCmZnlnBTMzCznpGBmZjknBTMzyzkpmJlZzknBzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWc5JwczMci1LCpIukrRG0tLCvLGSrpf0UPp36zRfks6TtFzSYkm7tSouMzPrXStbChcDU2vmnQLcEBFTgBvSNMDBwJT0mgV8s4VxmZlZL1qWFCLiZuDJmtnTgbmpPBc4rDD/O5G5DRgjabtWxWZmZvW1u09h24hYncqPAdum8njg0cJ6K9O8V5A0S9JCSQvXrl3bukjNzEagyjqaIyKAGMB2cyKiOyK6u7q6WhCZmdnI1WdSkLSZpA1S+fWSpknacID1Pd5zWij9uybNXwVsX1hvQppnZmZtVKalcDOwiaTxwHXAR8g6kQdiHjAjlWcA1xTmfzRdhbQn8HThNJOZmbVJmaSgiPgz8H7g/Ig4Ati5z42kS4FbgTdIWilpJjAbeLekh4AD0zTAT4AVwHLgAuAT/X4nZmbWtNEl1pGkvYAPAzPTvFF9bRQRR/Wy6IA66wZwXIlYzMyshcq0FD4FnAr8T0TcJ2kHYH5rwzIzsyr02VKIiJuAmyRtmqZXAMe3OjAzM2u/Mlcf7SXpfuDBNP1WSee3PDIzM2u7MqePvgYcBPwBICLuBfZpZVBmZlaNUjevRcSjNbNebEEsZmZWsTJXHz0q6e1ApJvWTgAeaG1YZmZWhTIthY+TXS46nuwu413w5aNmZsNSmauPniC7R8HMzIa5XpOCpK/TYMC6iPBlqWZmw0yjlsLCtkVhZmZDQq9JISLm9rbMzMyGp0anj74WEZ+S9EPqnEaKiGktjczMzNqu0emj76Z/v9yOQMzMrHqNTh/dlYq7RMS5xWWSTgBuamVgZmbWfmXuU5hRZ97RgxyHmZkNAY36FI4CPgRMljSvsGgL4MlWB2ZmZu3XqE/hFmA1MA44pzD/WWBxK4MyM7NqNOpTeAR4BNirfeGYmVmVSo2SamZmI4OTgpmZ5XpNCpJuSP+eNdiVSvq0pPskLZV0qaRNJE2WdLuk5ZIul7TRYNdrZmaNNWopbJeeozBN0q6Sdiu+BlqhpPFkz3jujog3AaOAI4GzgK9GxOuAPwIzB1qHmZkNTKOrj04DvghMAL5SsyyA/Zus91WSXgA2JbvKaX+yS2AB5gJnAN9sog4zM+unRlcfXQVcJemLEfGlwaowIlZJ+jLwO+AvwHXAXcBTEbEurbaS7KE+ryBpFjALYOLEiYMVlpmZUaKjOSK+JGmapC+n1/uaqVDS1sB0YDLwGmAzYGrZ7SNiTkR0R0R3V1dXM6GYmVmNPpOCpDPJnst8f3qdIOnfm6jzQOC3EbE2Il4AfgDsDYyR1NNymUD26E8zM2ujMpekHgK8OyIuioiLyH7VN9Na+B2wp6RNJQk4gCzZzAcOT+vMAK5pog4zMxuAsvcpjCmUt2qmwoi4HbgKWAQsSTHMAU4GPiNpObANcGEz9ZiZWf81uvqox5nA3ZLmAwL2AU5pptKIOB04vWb2CmCPZvZrZmbN6TMpRMSlkhYAb0uzTo6Ix1oalZmZVaJMS4GIWA3M63NFMzPraB77yMzMck4KZmaWa5gUJI2S9GC7gjEzs2o1TAoR8SKwTJLHkzAzGwHKdDRvDdwn6Q7guZ6ZETGtZVGZmVklyiSFL7Y8CjMzGxLK3Kdwk6TXAlMi4ueSNiV7BoKZmQ0zZQbE+weyYSn+f5o1Hri6lUGZmVk1ylySehzZKKbPAETEQ8CrWxmUmZlVo0xSeD4i/tYzkYa3jtaFZGZmVSmTFG6S9Dmyx2e+G7gS+GFrwzIzsyqUSQqnAGvJhrn+GPAT4AutDMrMzKpR5uqjlyTNBW4nO220LCJ8+sjMbBjqMylIOgT4FvAbsucpTJb0sYj4aauDMzOz9ipz89o5wH4RsRxA0o7AjwEnBTOzYaZMn8KzPQkhWQE826J4zMysQr22FCS9PxUXSvoJcAVZn8IRwJ1tiM3MzNqs0emjQwvlx4F3pfJa4FUti8jMzCrTa1KIiGPaGYiZmVWvzNVHk4FPApOK6zczdLakMcC3gTeRnZI6FlgGXJ7qeRj4QET8caB1mJlZ/5W5+uhq4EKyu5hfGqR6zwWujYjDJW0EbAp8DrghImZLOoXsprmTB6k+MzMroUxS+GtEnDdYFUraCtgHOBogjav0N0nTgX3TanOBBTgpmJm1VZmkcK6k04HrgOd7ZkbEogHWOZmss/q/JL0VuAs4Adg2IlandR4Dtq23saRZwCyAiRP9lFAzs8FUJim8GfgIsD/rTx9Fmh5onbsBn4yI2yWdS3aqKBcRIanuUBoRMQeYA9Dd3e3hNszMBlGZpHAEsENx+OwmrQRWRsTtafoqsqTwuKTtImK1pO2ANYNUn5mZlVTmjualwJjBqjAiHgMelfSGNOsA4H5gHjAjzZsBXDNYdZqZWTllWgpjgAcl3cnL+xQGfEkq2SWul6Qrj1YAx5AlqCskzQQeAT7QxP7NzGwAyiSF0we70oi4B+ius+iAwa7LzMzKK/M8hZvaEYiZmVWvzB3Nz7L+mcwbARsCz0XElq0MzMzM2q9MS2GLnrIkAdOBPVsZlJmZVaPM1Ue5yFwNHNSieMzMrEJlTh+9vzC5AVkH8V9bFpGZmVWmzNVHxecqrCMbwXR6S6IxM7NKlelT8HMVzMxGiEaP4zytwXYREV9qQTxmZlahRi2F5+rM2wyYCWwDOCmYmQ0zjR7HeU5PWdIWZMNbHwNcBpzT23ZmZta5GvYpSBoLfAb4MNmDb3bzIzLNzIavRn0KZwPvJ3t2wZsj4k9ti8rMzCrR6Oa1E4HXAF8Afi/pmfR6VtIz7QnPzMzaqVGfQr/udjYzs87nL34zM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeUqSwqSRkm6W9KP0vRkSbdLWi7pckkbVRWbmdlIVWVL4QTggcL0WcBXI+J1wB/JBt4zM7M2qiQpSJoAHAJ8O00L2B+4Kq0yFzisitjMzEayqloKXwM+C7yUprcBnoqIdWl6JTC+isDMzEayticFSe8D1kTEXQPcfpakhZIWrl27dpCjMzMb2apoKewNTJP0MNmzGfYHzgXGSOoZi2kCsKrexhExJyK6I6K7q6urHfGamY0YbU8KEXFqREyIiEnAkcCNEfFhYD5weFptBnBNu2MzMxvphtJ9CicDn5G0nKyP4cKK4zEzG3EaPnmt1SJiAbAglVcAe1QZj5nZSDeUWgpmZlYxJwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmOScFMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOznJOCmZnlnBTMzCznpGBmZjknBTMzyzkpmJlZzknBzMxyo6sOYCSadMqPB7ztw7MPGcRIzMxeru0tBUnbS5ov6X5J90k6Ic0fK+l6SQ+lf7dud2xmZiNdFaeP1gEnRsROwJ7AcZJ2Ak4BboiIKcANadrMzNqo7UkhIlZHxKJUfhZ4ABgPTAfmptXmAoe1OzYzs5Gu0j4FSZOAXYHbgW0jYnVa9BiwbS/bzAJmAUycOLH1QQ4jzfRlgPszzEaCyq4+krQ58H3gUxHxTHFZRAQQ9baLiDkR0R0R3V1dXW2I1Mxs5KikpSBpQ7KEcElE/CDNflzSdhGxWtJ2wJoqYrPW8BVXZp2hiquPBFwIPBARXyksmgfMSOUZwDXtjs3MbKSroqWwN/ARYImke9K8zwGzgSskzQQeAT5QQWxmZiNa25NCRPwSUC+LD2hnLNYZfOrJrH18R3OHafYKIjOzRjz2kZmZ5ZwUzMws59NHNqy5P8Ksf9xSMDOznFsKVpo7uc2GP7cUzMws56RgZmY5nz4y64VHlbWRyElhgHx+3VrJV01ZVXz6yMzMck4KZmaW8+kjsxbxKUbrRG4pmJlZzknBzMxyTgpmZpZzn4LZMOPLWa0ZbimYmVnOLQUzy7mVYU4KZjYoqrwE1wlp8Pj0kZmZ5YZcS0HSVOBcYBTw7YiYXXFIZmZ1DcfW0ZBqKUgaBXwDOBjYCThK0k7VRmVmNnIMqaQA7AEsj4gVEfE34DJgesUxmZmNGEPt9NF44NHC9Erg74orSJoFzEqTf5K0bIB1jQOeGOC2VXPs7depcUPnxl46bp3V4kj6r+XHvMn3fG1ETK23YKglhT5FxBxgTrP7kbQwIroHIaS2c+zt16lxQ+fG3qlxQ2fHPtROH60Cti9MT0jzzMysDYZaUrgTmCJpsqSNgCOBeRXHZGY2Ygyp00cRsU7SPwI/I7sk9aKIuK9F1TV9CqpCjr39OjVu6NzYOzVu6ODYFRFVx2BmZkPEUDt9ZGZmFXJSMDOz3LBMCpKmSlomabmkU+os31jS5Wn57ZImFZadmuYvk3RQO+NO9Q8odkmTJP1F0j3p9a0hFvc+khZJWifp8JplMyQ9lF4z2hd1Xn8zsb9YOOZtvSiiRNyfkXS/pMWSbpD02sKyoX7MG8U+lI/5xyUtSbH9sjgiQ9XfLaVFxLB6kXVQ/wbYAdgIuBfYqWadTwDfSuUjgctTeae0/sbA5LSfUR0S+yRg6RA+5pOAtwDfAQ4vzB8LrEj/bp3KW3dC7GnZn4bwMd8P2DSV/1/hs9IJx7xu7B1wzLcslKeR3SRW+XdLf17DsaVQZqiM6cDcVL4KOECS0vzLIuL5iPgtsDztr12aib1KfcYdEQ9HxGLgpZptDwKuj4gnI+KPwPVA3TstW6SZ2KtUJu75EfHnNHkb2X0/0BnHvLfYq1Qm7mcKk5sBPVfyVP3dUtpwTAr1hsoY39s6EbEOeBrYpuS2rdRM7ACTJd0t6SZJ72x1sPViSvpz3DrhmDeyiaSFkm6TdNjghtZQf+OeCfx0gNsOtmZihyF+zCUdJ+k3wH8Ax/dn26FgSN2nYE1ZDUyMiD9I2h24WtLONb9cbPC9NiJWSdoBuFHSkoj4TdVBFUn6e6AbeFfVsfRXL7EP6WMeEd8AviHpQ8AXgLb32TRjOLYUygyVka8jaTSwFfCHktu20oBjT83SPwBExF1k5yxf3/KIa2JK+nPcOuGY9yoiVqV/VwALgF0HM7gGSsUt6UDg88C0iHi+P9u2UDOxD/ljXnAZ0NOSqfqYl1d1p8Zgv8haPyvIOnN6OoN2rlnnOF7eWXtFKu/MyzuDVtDejuZmYu/qiZWsI2wVMHaoxF1Y92Je2dH8W7IOz61TuS1xD0LsWwMbp/I44CFqOh4r/qzsSvbjYErN/CF/zBvEPtSP+ZRC+VBgYSpX+t3Sr/dZdQAt+uO9F/h1+lB9Ps37F7JfHACbAFeSdfbcAexQ2PbzabtlwMGdEjvwf4D7gHuARcChQyzut5GdR32OrFV2X2HbY9P7WQ4cMwSPed3YgbcDS9J/9iXAzCEW98+Bx9Nn4h5gXgcd87qxd8AxP7fw/3A+haRR9XdL2ZeHuTAzs9xw7FMwM7MBclIwM7Ock4KZmeWcFMzMLOekYGZmOScFMytN0mhJP5O0c9Wx9IekWZL+teo4OoGTQocrDCO8VNIPJY3pY/1dJL23MD2t3hDAA4hjY0k/T7F8sOQ2A65b0gJJ3SXXPaxmCOPS26b1J6UhCyoj6QhJD0iaX3L9i2uH+R4MkY239RHgTEkbpromSVran/0U//aSzpB0Up118v1K6pZ0XhNxzwHGSvq7ge5jpHBS6Hx/iYhdIuJNwJNkdzw3sgvZDTgARMS8iJg9CHHsmva3S0RcXmaDQay7L4eRDV08UJOAAScFZZr9vzYT+IeI2K/J/TQtItZExLSIeKGJffTrbx8RCyPi+L7XbLiPT0TE7c3sYyRwUhhebiWNvChpD0m3plFTb5H0Bkkbkd19+cGeX/SSjpb0n2mbSZJuLDzYZGJtBZLGSro6rXObpLdIejXwPeBtab871myzQNK5hRbNHml+se5rJH00lT8m6ZJUfk96H4skXSlp85p9j0q/ipcqe7jJp2uWv51sXPuza2I7QtIdkn7dM6Jsev+/SHUtStsCzAbembav3f/m6VgtSvVPL+xrmaTvAEuB7SX9k6Q707H753p/QElHpf0slXRWmnca8A7gQkln19nm5LTNvZJe8UUr6bRU71JJc6RsqHVJx2v9g2wuS/PepfUPsLlb0hb14qxjtKRLUmvmKkmbpv09LGlcKndLWpDK+d++Jtbd0/u4l8IPHEn7SvpRKp8h6aL0uVoh6fjCel9Mx/2Xki5VnRaI9aHqW6r9au5FeuAI2QNArgSmpuktgdGpfCDw/VQ+GvjPwvb5NPBDYEYqHwtcXae+rwOnp/L+wD2pvC/wo15iXABckMr7kB4GVFP3tmRDLryTbBiBsWRj29wMbJbWORk4rbDPbmB3smcD9NQ1pk79F/PyMYsWAOek8nuBn6fypsAmqTyF9ePWNHpvo0kPVknxLgdE1rp4CdgzLXsPMCct2wD4EbBPzb5eA/yObByr0cCNwGHF91un/oOBW1j/QJqxte+ZwrhGwHdJQ6AAv2f9OEJjCp+BvVN5c9JnqI/P4CSy5wb0bHcRcFIqPwyMS+VuYEGdv/0ZhfUX9xwX4GzWf1byv0Fa/xaycYTGkQ09siHZcCT3kA0FswXZuEgnVf1/tNNebil0vldJugd4jOyL9fo0fyvgSmXnZL9KNiBXX/YC/juVv0v267TWO9IyIuJGYBtJW5bY96Vpm5uBLVXT9xERjwOnkY0Xc2JEPAnsSXba51fpPc4AXluz3xXADpK+LmkqUHao8B+kf+8i+1KD7IvlAklLyBJsmVNOAv5d0mKy8XrGk/0dAB6JiNtS+T3pdTfZ2FRvJEs8RW8j+9JcG9m5+0vIkmgjBwL/FemBNOm41dpP2aNbl5Al8p7PwmLgEmXDU69L834FfCX9+h6T4ijj0Yj4VSp/j/qfnYbSZ2JM+oxA+pz14seRjQz8BLCG7JjvDVwTEX+NiGfJEpz1k5NC5/tLROxC9mUp1je5vwTMj6yv4VCyX09Vqh1kq96gW28m+9X3mjQtslbALum1U0TMfNlOsieHvZXsl/THgW+XjKdnKOYXWf9ckU+TDcL2VrJftRuV2M+HyX7Z757+Do+z/lg/V1hPwJmF9/K6iLiwZKwDJmkT4HyyVsObgQsK8R0CfAPYDbhT0ujIzvP/X+BVZMn4jSWr6u3vu4713zOD+Rl8vlAu/g2tSU4Kw0T6pXg8cKLWP2ehZ7z2owurPkvWtK7nFrLhuCH7svtFnXV+kZYhaV/giSj3IJ8Ppm3eATwdEU8XF6Z+hoPJOqxPkjSZ7DGMe0t6XVpnM0mvr9luHLBBRHyf7IEmu9Wpu9F7LtoKWB0RL5FdYTOqxPZbAWsi4gVJ+/HKlkyPnwHH9vSJSBqvrC+m6A7gXZLGSRoFHAXc1EfM1wPHFM7hj61Z3vNF/ESq+/C03gbA9hExn+y03FbA5pJ2jIglEXEWcCdZi6aMiZL2SuUPAb9M5YfJTvFBNpJvryLiKeCp9BmB9Dnrh18Bh0raJL3X9/Vze8NJYViJiLvJTgkcRfYowDMl3c3Lf0XNB3ZS/UtHP0n2BbOY7EvxhDrVnAHsntaZTfmnSv01xfItsitpcpI2JvsFe2xE/B44key89BNkCe3SVN+tvPJLajywIJ1e+h5wap26LwP+KXWc7lhneY/zgRmpk/ONrP+lvxh4MXWAfrpmm0uA7nRq5qPAg/V2HBHXkZ2auzWtexU1iSYiVgOnkP2N7gXuiohrGsRLRFwLzAMWpmNwUs3yp8iO7VKyxHRnWjQK+F6K5W7gvLTup1KH9GLgBV7+GMxGlgHHSXqA7JkH30zz/xk4V9JCsl/0fTmG7Kll95C1rkqLiDvJjsXiFPcSssfVWj946GxruXTFyUkRsbDqWGx4k7R5RPwptZxuBmZFxKKq4+okPg9nZsPJHGU3Km4CzHVC6D+3FMzMLOc+BTMzyzkpmJlZzknBzMxyTgpmZpZzUjAzs9z/AlyId/D5frQxAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Percentage of Pixels Belonging to Buildings: 0.064\n"
          ]
        }
      ],
      "source": [
        "tile_type = '512_512_eroded' # other options: '512_512 stride augmented', '256_256 stride', '512_512 stride augmented test', '512_512 stride augmented train'\n",
        "percentages = check_dataset_balance(tile_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGdyyhgBdGKR"
      },
      "source": [
        "## 4. Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnDa6_SSNi4s"
      },
      "source": [
        "### 4.1. U-Net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZjuY4rgN-Ku"
      },
      "source": [
        "Run this nex cell to train a U-Net model for 100 epochs. The model will be saved in `model_dir`. The resulting .pkl file can then be used in the BEAM tool. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tile_type = '512_with_erosion'\n",
        "backbone = 'resnet18'\n",
        "fit_type = 'one_cycle'\n",
        "learning_rate = None\n",
        "epochs = 100\n",
        "architecture = 'U-Net'\n",
        "loss_function = None\n",
        "model_dir = f'{path}/models/experiment_results/{architecture}/{backbone}'\n",
        "create_missing_folder(model_dir)\n",
        "\n",
        "learn, dls = u_net_model_training(tile_type, backbone, fit_type, learning_rate, epochs, loss_function, architecture='U-Net', split=.2)\n",
        "\n",
        "learn.export(f'{model_dir}/{architecture}_{timestamp()}_exported.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predictions\n",
        "This section shows how to run inference to generate predictions and perform evaluation on a test set.\n",
        "\n",
        "These functions work together to create a pipeline for generating predictions from aerial imagery and saving them as shapefiles of detected buildings. They do this by creating tiles from an image, saving predictions for each tile, merging the predictions into a single image, and creating a shapefile from the merged image. The `create_tiles` function cuts the input image into tiles of a specified size and saves them to disk. The `save_predictions` function loads the saved tiles, runs them through a pre-trained model, and saves the resulting predictions to disk. The `merge_tiles` function combines the predictions from all tiles into a single image. The `get_saved_predictions` function loads the saved predictions from disk and returns them as a NumPy array. Finally, the `create_shp_from_mask` function converts the merged image into a shapefile of detected settlements. The resulting shapefile can be used to visualize the detected buildings in the original image.\n",
        "\n",
        "The `merge_tiles` function is used to combine the predictions from all tiles into a single image. It takes as input a NumPy array of shape `(n, nrows, ncols, c)` or `(n, nrows, ncols)` and the original height and width of the image. If the input array has a color channel, the function reshapes it into a 4D array and then combines the tiles into a single image. If the input array does not have a color channel, the function reshapes it into a 3D array and then combines the tiles into a single image. \n",
        "\n",
        "The `save_predictions` function loads the saved tiles, runs them through the loaded model, and saves the resulting predictions to disk. The `create_tiles` function cuts the input image into tiles of a specified size and saves them to disk. The `get_image_tiles` function returns a sorted list of the first `n` image tile filenames in a directory. The `get_saved_predictions` function loads the saved predictions from disk and returns them as a NumPy array. Finally, the `create_shp_from_mask` function converts the merged image into a shapefile of detected settlements. \n",
        "\n",
        "The `create_inferences` function calls these functions in sequence to perform the entire process of creating tiles, saving predictions, merging tiles, and creating a shapefile. It first creates tiles from the input image using `create_tiles`, then saves predictions for each tile using `save_predictions`. It then merges the predictions into a single image using `merge_tiles` and creates a shapefile from the merged image using `create_shp_from_mask`. The resulting shapefile can be used to visualize the detected settlements in the original image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_names = []\n",
        "tile_dir = f\"{path}/image_tiles_inference\" # set the path to the folder containing the tiles\n",
        "inf_tile_size = 1000\n",
        "predicted_dir =  f\"{path}/saved_preds\" # set the path to the folder where the predicted masks should be saved\n",
        "file = f'{path}/your_file.tif' # set the path to the image that should be used for inference\n",
        "image_shape_x = None\n",
        "image_shape_y = None\n",
        "loaded_model = load_learner(f\"your_saved_model\") # or set to learn if you want to use the model you just trained\n",
        "output_folder = f\"{model_dir}/predictions\" # set the path to the folder where the predicted masks should be saved\n",
        "create_missing_folder(output_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_tiles(image_path):\n",
        "    \"\"\"\n",
        "    cuts the big image (from the path) into tiles with tile size as stated in the global variables. the images are\n",
        "    squared.\n",
        "    the tiles will be saved under /images_tiles/image_name/...png\n",
        "    \"\"\"\n",
        "    tilling_start_time = datetime.now()\n",
        "    global tile_dir, loaded_model\n",
        "    global inf_tile_size\n",
        "    global image_shape_x, image_shape_y\n",
        "    if not exists(tile_dir):\n",
        "        makedirs(tile_dir)\n",
        "    # add condition to test the file size if it is 0 then just return?\n",
        "    img = np.array(PILImage.create(image_path))\n",
        "    image_shape_x, image_shape_y, _ = img.shape\n",
        "    img_name = image_path.split(\"/\")[-1]\n",
        "    if exists(join(tile_dir, img_name)):\n",
        "        filelist = glob.glob(join(tile_dir, img_name, img_name + \"*.png\"))\n",
        "        for f in filelist:\n",
        "            remove(f)\n",
        "    else:\n",
        "        makedirs(join(tile_dir, img_name))\n",
        "    # Cut tiles and save them\n",
        "    for i in range(image_shape_x // inf_tile_size):\n",
        "        for j in range(image_shape_y // inf_tile_size):\n",
        "            img_tile = img[\n",
        "                       i * inf_tile_size: (i + 1) * inf_tile_size, j * inf_tile_size: (j + 1) * inf_tile_size\n",
        "                       ]\n",
        "            Image.fromarray(img_tile).save(\n",
        "                f\"{join(tile_dir, img_name)}/{img_name}_000{i * (image_shape_x // inf_tile_size) + j}.png\"\n",
        "            )\n",
        "    tilling_end_time = datetime.now()\n",
        "\n",
        "\n",
        "def get_image_tiles(nbr_tiles, img_name) -> L:\n",
        "    \"\"\"\n",
        "    Helper function to return a sorted list of the first `n` image tile filenames in `path`\n",
        "\n",
        "    \"\"\"\n",
        "    global tile_dir\n",
        "    files = L()\n",
        "    files.extend(get_image_files(path=tile_dir, folders=img_name)[:nbr_tiles])\n",
        "    return files\n",
        "\n",
        "\n",
        "def save_predictions(image_path):\n",
        "    \"\"\"\n",
        "    Saves the intermediary detected images from all tiles. Predicts all tiles of one scene and saves them to disk.\n",
        "    \"\"\"\n",
        "    global loaded_model\n",
        "    if not exists(predicted_dir):\n",
        "        makedirs(predicted_dir)\n",
        "    img_name = image_path.split(\"/\")[-1]\n",
        "    # get all the tiles from the directory they belong to.\n",
        "    tiles = os_sorted(get_image_tiles(len(listdir(join(tile_dir, img_name))), img_name))\n",
        "    # predict all tiles and save them to disk\n",
        "    for i in range(len(tiles)):\n",
        "        pred, _, outputs = loaded_model.predict(tiles[i]) # predict the mask for the tile\n",
        "        output = torch.exp(pred[:, :]).detach().cpu().numpy() # convert the mask to a numpy array\n",
        "        np.save(f\"{predicted_dir}/saved_{i:02d}\", output) # save the mask\n",
        "    outputs = os_sorted(glob.glob(f\"{predicted_dir}/*.npy\")) # get the filenames of the saved masks\n",
        "    return len(tiles) == len(outputs) # return True if the number of tiles is equal to the number of saved masks\n",
        "\n",
        "\n",
        "def merge_tiles(arr, h, w):\n",
        "    \"\"\"\n",
        "    Takes as input a NumPy array of shape (n, nrows, ncols, c) or (n, nrows, ncols) \n",
        "    and the original height and width of the image. \n",
        "    If the array has a color channel, will reshape into a 3d array of shape HWC.\n",
        "    If no color channel, will reshape into array of shape: h, w.\n",
        "    NB: Currently only works without color channel (NHWC wrong shape for PyTorch tensors) \n",
        "    \"\"\"\n",
        "\n",
        "    try:  # with color channel\n",
        "        n, nrows, ncols, c = arr.shape # get the shape of the array\n",
        "        return (\n",
        "            arr.reshape(h // nrows, -1, nrows, ncols, c).swapaxes(1, 2).reshape(h, w, c) # reshape the array\n",
        "        )\n",
        "    except ValueError:  # without color channel\n",
        "        n, nrows, ncols = arr.shape # get the shape of the array\n",
        "        return arr.reshape(h // nrows, -1, nrows, ncols).swapaxes(1, 2).reshape(h, w) # reshape the array\n",
        "\n",
        "\n",
        "def get_saved_predictions():\n",
        "    \"\"\"\n",
        "    Load saved prediction mask tiles for a scene and return assembled \n",
        "    mask based on the original image size by using the merge_tiles function.\n",
        "    \"\"\"\n",
        "    mask_tiles = os_sorted(glob.glob(f\"{predicted_dir}/*.npy\")) # get the filenames of the saved masks\n",
        "    mask_array = list(map(np.load, mask_tiles)) # load the saved masks\n",
        "    global image_shape_x, image_shape_y, inf_tile_size \n",
        "    # Remove hard coded values\n",
        "    if mask_array is None or len(mask_array) == 0:\n",
        "        return None\n",
        "    try: \n",
        "        mask_array = merge_tiles(\n",
        "            np.array(mask_array),\n",
        "            (image_shape_x // inf_tile_size) * inf_tile_size, \n",
        "            (image_shape_y // inf_tile_size) * inf_tile_size,\n",
        "        )\n",
        "    except ValueError as err:\n",
        "        print(f\"Unexpected {err=}, {type(err)=}\")\n",
        "\n",
        "    return mask_array\n",
        "\n",
        "\n",
        "def create_shp_from_mask(file, mask_array):\n",
        "    \"\"\"\n",
        "    Transforms the image to a geo-encoded image by\n",
        "    Creates a shapefile from a binary mask array and saves it to disk. The shapefile contains polygons that represent \n",
        "    the connected regions of the mask. The function takes as input a file path to the original image and a binary mask \n",
        "    array of the same size as the original image. The function first dilates the mask with a 3x3 square kernel, which \n",
        "    is the inverse of the erosion applied in preprocessing. Then, it uses the `rasterio.features.shapes` function to \n",
        "    extract the shapes of the connected regions of the mask. Finally, it saves the shapes as polygons in a shapefile \n",
        "    with the same name as the original image file, suffixed with \"_predicted.shp\". If the mask array is None or has \n",
        "    length 1, the function creates an empty shapefile with the same name as the original image file, suffixed with \n",
        "    \"_predicted.shp\".\n",
        "    \"\"\"\n",
        "    global output_folder\n",
        "    if not os.path.exists(output_folder):\n",
        "      os.makedirs(output_folder)\n",
        "    with rasterio.open(file, \"r\") as src:\n",
        "        raster_meta = src.meta\n",
        "    # create an empty shapefile and interrupt the function.\n",
        "    if mask_array is None or len(mask_array) == 1:\n",
        "        pred_name = file.split(\"/\")[-1]\n",
        "        empty_schema = {\"geometry\": \"Polygon\", \"properties\": {\"id\": \"int\"}}\n",
        "        no_crs = None\n",
        "        gdf = gpd.GeoDataFrame(geometry=[])\n",
        "        gdf.to_file(\n",
        "            f\"{output_folder}/{pred_name}_predicted.shp\",\n",
        "            driver=\"ESRI Shapefile\",\n",
        "            schema=empty_schema,\n",
        "            crs=no_crs,\n",
        "        )\n",
        "        return\n",
        "    mask_array = np.array(mask_array)\n",
        "    # Dilate the mask with a 3x3 square kernel. This is the inverse of the erosion applied in preprocessing\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    mask_array = cv2.dilate(mask_array, kernel, iterations=1)\n",
        "    shapes = rasterio.features.shapes(mask_array, transform=raster_meta[\"transform\"])\n",
        "    polygons = [\n",
        "        shapely.geometry.Polygon(shape[0][\"coordinates\"][0]) for shape in shapes\n",
        "    ]\n",
        "    my_list = raster_meta[\"crs\"]\n",
        "    gdf = gpd.GeoDataFrame(crs=my_list, geometry=polygons)\n",
        "    gdf[\"area\"] = gdf[\"geometry\"].area\n",
        "    gdf = gdf.drop([gdf[\"area\"].idxmax()])\n",
        "    # Drop shapes that are too small or too large to be a building\n",
        "    gdf = gdf[(gdf[\"area\"] > 2) & (gdf[\"area\"] < 500000)]\n",
        "    pred_name = file.split(\"/\")[-1]\n",
        "    # in case the geo-dataframe is empty which means no settlements are detected\n",
        "    if gdf.empty:\n",
        "        empty_schema = {\"geometry\": \"Polygon\", \"properties\": {\"id\": \"int\"}}\n",
        "        no_crs = None\n",
        "        gdf = gpd.GeoDataFrame(geometry=[])\n",
        "        gdf.to_file(\n",
        "            f\"{output_folder}/{pred_name}_predicted.shp\",\n",
        "            driver=\"ESRI Shapefile\",\n",
        "            schema=empty_schema,\n",
        "            crs=no_crs,\n",
        "        )\n",
        "    else:\n",
        "        gdf.to_file(\n",
        "            f\"{output_folder}/{pred_name}_predicted.shp\", driver=\"ESRI Shapefile\"\n",
        "        )\n",
        "\n",
        "def create_inferences(file: str):\n",
        "    \"\"\"\n",
        "    Creates the inferences for the given file and saves them in the output folder.\n",
        "    This is the main function that should be called to start the inference process.\n",
        "    Takes as input a file path to the original image.\n",
        "    \"\"\"\n",
        "    headers = {\"Access-Control-Allow-Origin\": \"*\"}\n",
        "    process_start = datetime.now()\n",
        "    global image_shape_x, image_shape_y\n",
        "    inf_start = datetime.now()\n",
        "    if (os.stat(file).st_size == 0):\n",
        "        pred_name = file.split(\"/\")[-1]\n",
        "        empty_schema = {\"geometry\": \"Polygon\", \"properties\": {\"id\": \"int\"}}\n",
        "        no_crs = None\n",
        "        gdf = gpd.GeoDataFrame(geometry=[])\n",
        "        gdf.to_file(\n",
        "            f\"{output_folder}/{pred_name}_predicted.shp\",\n",
        "            driver=\"ESRI Shapefile\",\n",
        "            schema=empty_schema,\n",
        "            crs=no_crs,\n",
        "        )\n",
        "\n",
        "        content = {\"message\": \"An empty Shape file for the empty image is stored.\"}\n",
        "\n",
        "\n",
        "    create_tiles(file)\n",
        "    saved_pred = save_predictions(file)\n",
        "    inf_finish = datetime.now()\n",
        "    img_name = file.split(\"/\")[-1]\n",
        "    if not saved_pred:\n",
        "        content = {\n",
        "            \"message\": \"The tiles and outputs have mismatched, please start the segmenting process again!\"\n",
        "        }\n",
        "        shutil.rmtree(join(tile_dir, img_name))\n",
        "        filelist = glob.glob(join(predicted_dir, \"*.npy\"))\n",
        "        for f in filelist:\n",
        "            os.remove(f)\n",
        "\n",
        "\n",
        "    else:\n",
        "        create_shp_from_mask(file, get_saved_predictions())\n",
        "        content = {\"message\": \"Output saved in the Output Folder.\"}\n",
        "\n",
        "        shutil.rmtree(join(tile_dir, img_name))\n",
        "        filelist = glob.glob(join(predicted_dir, \"*.npy\"))\n",
        "        for f in filelist:\n",
        "            os.remove(f)\n",
        "        process_finish = datetime.now()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "create_inferences(file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "055358546d954bde80ceaae167bc4218": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5909098c172431aa3c1e64f94495db6",
            "placeholder": "",
            "style": "IPY_MODEL_d098cf2e49f144f1b141db39cf8b1896",
            "value": "100%"
          }
        },
        "05ac9aa6f0864833a6071c2408ff2c05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b2780cbf8d6472698ab97c8844084df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a7995efcf6243a29a7805b07ee44c78",
              "IPY_MODEL_3a1dd93bc5874efcab396edc0311f9be",
              "IPY_MODEL_23ab536259874bcebc1085e43de7d02e"
            ],
            "layout": "IPY_MODEL_b1fe101d7a0b4b20ab6b80c2bfc23b67"
          }
        },
        "1351e2b7ea4d47f6b1559a105993aeca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23ab536259874bcebc1085e43de7d02e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7865a89582e43678e2b1480346f4354",
            "placeholder": "",
            "style": "IPY_MODEL_99906e642991486c974a630ed5137a51",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 168MB/s]"
          }
        },
        "29d883faa9dc4dce92de3ace1ed6b4e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e845f56b652b4e439fe8400485762f4d",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0e5eae2c98d432b8030d24f44260a72",
            "value": 46830571
          }
        },
        "2c9385523c7849429c46bf943ec2c8e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a1dd93bc5874efcab396edc0311f9be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcebffac2164450bbcf6e5d3817488fc",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05ac9aa6f0864833a6071c2408ff2c05",
            "value": 46830571
          }
        },
        "4a7995efcf6243a29a7805b07ee44c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a555c354bf654eb0932858cfb8a19803",
            "placeholder": "",
            "style": "IPY_MODEL_895ef6feb00e479899f121cd6c70a047",
            "value": "100%"
          }
        },
        "4be7de650fdb45dcb11c44f043ac4649": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74a4356baadb4ca6b5ec1bb9b22fd89a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "787f8d39342a41e3958ada8862f6ec26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_055358546d954bde80ceaae167bc4218",
              "IPY_MODEL_fee9eac1c0254bb2aa248ca08c052246",
              "IPY_MODEL_b64e51a7c15846b9ae9021c0cb6b5af9"
            ],
            "layout": "IPY_MODEL_c073a8d02ca94c70968f0c625c66f6a1"
          }
        },
        "895ef6feb00e479899f121cd6c70a047": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99906e642991486c974a630ed5137a51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a555c354bf654eb0932858cfb8a19803": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a61cdda1d79e4ea6bdd6c159ee8cd1d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1fe101d7a0b4b20ab6b80c2bfc23b67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b64e51a7c15846b9ae9021c0cb6b5af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee0234495d824580b849dd5d8b4be34b",
            "placeholder": "",
            "style": "IPY_MODEL_c36f6800dc784300a5dbd20ded74e565",
            "value": " 83.3M/83.3M [00:01&lt;00:00, 54.6MB/s]"
          }
        },
        "c073a8d02ca94c70968f0c625c66f6a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c36f6800dc784300a5dbd20ded74e565": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5909098c172431aa3c1e64f94495db6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c595a9ad9c7547e2984c882f734e59e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6344c83640d4de7a65f049ab34586aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff5bd6dbe48f429dbf6d5e07fffdb92b",
              "IPY_MODEL_29d883faa9dc4dce92de3ace1ed6b4e5",
              "IPY_MODEL_eedb376784cb4582abc10a45c441a7db"
            ],
            "layout": "IPY_MODEL_d63f54603d3844daba013b624a3247ee"
          }
        },
        "c7865a89582e43678e2b1480346f4354": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d098cf2e49f144f1b141db39cf8b1896": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d63f54603d3844daba013b624a3247ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcebffac2164450bbcf6e5d3817488fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0e5eae2c98d432b8030d24f44260a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e845f56b652b4e439fe8400485762f4d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee0234495d824580b849dd5d8b4be34b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eedb376784cb4582abc10a45c441a7db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1351e2b7ea4d47f6b1559a105993aeca",
            "placeholder": "",
            "style": "IPY_MODEL_74a4356baadb4ca6b5ec1bb9b22fd89a",
            "value": " 44.7M/44.7M [00:01&lt;00:00, 33.3MB/s]"
          }
        },
        "fee9eac1c0254bb2aa248ca08c052246": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c9385523c7849429c46bf943ec2c8e7",
            "max": 87319819,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c595a9ad9c7547e2984c882f734e59e2",
            "value": 87319819
          }
        },
        "ff5bd6dbe48f429dbf6d5e07fffdb92b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4be7de650fdb45dcb11c44f043ac4649",
            "placeholder": "",
            "style": "IPY_MODEL_a61cdda1d79e4ea6bdd6c159ee8cd1d3",
            "value": "100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
