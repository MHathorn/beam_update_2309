{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Segmentation Training Migration\n",
    "Migrating training pipeline from fastai to PyTorch Lightning and TorchGeo.\n",
    "This notebook works with data prepared by the BEAM DataTiler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import rasterio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchgeo.datasets as datasets\n",
    "import torchgeo.transforms as transforms\n",
    "from torchvision import transforms as T\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, TQDMProgressBar\n",
    "import segmentation_models_pytorch as smp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Project configuration\n",
    "PROJECT_DIR = Path('/datadrive/training_data_by_city/sd')\n",
    "TRAIN_DIR = PROJECT_DIR / 'tiles/train'\n",
    "VAL_DIR = PROJECT_DIR / 'tiles/test'  # Using test split as validation\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 4\n",
    "IMG_SIZE = 256  # Assuming 256x256 tiles based on your config\n",
    "\n",
    "# Model configuration\n",
    "MODEL_CONFIG = {\n",
    "    'architecture': 'unet',\n",
    "    'backbone': 'resnet18',\n",
    "    'learning_rate': 1e-4,\n",
    "    'epochs': 50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildingSegmentationDataset(Dataset):\n",
    "    \"\"\"Dataset for building segmentation\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.image_dir = self.data_dir / 'images'\n",
    "        self.mask_dir = self.data_dir / 'masks'\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get all image files\n",
    "        self.image_files = sorted(list(self.image_dir.glob('*.TIF')))\n",
    "        self.mask_files = sorted(list(self.mask_dir.glob('*.TIF')))\n",
    "        \n",
    "        # Verify matching files\n",
    "        assert len(self.image_files) == len(self.mask_files), \\\n",
    "            f\"Number of images ({len(self.image_files)}) and masks ({len(self.mask_files)}) don't match\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image and mask\n",
    "        with rasterio.open(self.image_files[idx]) as src:\n",
    "            image = src.read()  # CxHxW format\n",
    "            \n",
    "        with rasterio.open(self.mask_files[idx]) as src:\n",
    "            mask = src.read(1)  # Single channel, HxW format\n",
    "        \n",
    "        # Convert to torch tensors\n",
    "        image = torch.from_numpy(image).float()\n",
    "        mask = torch.from_numpy(mask).long()\n",
    "        \n",
    "        # Normalize image to [0, 1] range\n",
    "        image = image / 255.0\n",
    "        \n",
    "        # Convert mask to binary (0 or 1)\n",
    "        mask = (mask > 0).long()\n",
    "        \n",
    "        if self.transform:\n",
    "            # Stack image and mask for joint transforms\n",
    "            stacked = torch.cat([image, mask.unsqueeze(0)], dim=0)\n",
    "            transformed = self.transform(stacked)\n",
    "            image = transformed[:3]  # First 3 channels are RGB\n",
    "            mask = transformed[3]    # Last channel is mask\n",
    "        \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataModule Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildingSegmentationDataModule(pl.LightningDataModule):\n",
    "    \"\"\"PyTorch Lightning DataModule for building segmentation\"\"\"\n",
    "    \n",
    "    def __init__(self, train_dir, val_dir, batch_size=8, num_workers=4):\n",
    "        super().__init__()\n",
    "        self.train_dir = train_dir\n",
    "        self.val_dir = val_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "        # Define transforms\n",
    "        self.train_transform = T.Compose([\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.RandomVerticalFlip(),\n",
    "            T.RandomRotation(45),\n",
    "            # Add more augmentations as needed\n",
    "        ])\n",
    "        \n",
    "        self.val_transform = None  # No augmentation for validation\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        # Create train and validation datasets\n",
    "        self.train_dataset = BuildingSegmentationDataset(\n",
    "            self.train_dir,\n",
    "            transform=self.train_transform\n",
    "        )\n",
    "        \n",
    "        self.val_dataset = BuildingSegmentationDataset(\n",
    "            self.val_dir,\n",
    "            transform=self.val_transform\n",
    "        )\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildingSegmentationModel(pl.LightningModule):\n",
    "    def __init__(self, architecture='unet', backbone='resnet18', learning_rate=1e-4):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Initialize actual model architecture\n",
    "        if architecture.lower() == 'unet':\n",
    "            self.model = smp.Unet(\n",
    "                encoder_name=backbone,      # Choose encoder (e.g., 'resnet18')\n",
    "                encoder_weights=\"imagenet\", # Use pre-trained weights\n",
    "                in_channels=3,             # RGB images\n",
    "                classes=1,                 # Binary segmentation\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Architecture {architecture} not implemented yet\")\n",
    "        \n",
    "        # Define loss function for binary segmentation\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, masks = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.criterion(outputs, masks.float().unsqueeze(1))  # Add channel dimension\n",
    "        \n",
    "        # Log training metrics\n",
    "        self.log('train/loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        # Log images periodically\n",
    "        if batch_idx % 100 == 0:\n",
    "            self._log_images(images, masks, outputs, 'train', batch_idx)\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, masks = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.criterion(outputs, masks.float().unsqueeze(1))\n",
    "        \n",
    "        # Calculate additional metrics\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        iou = self.calculate_iou(preds, masks.unsqueeze(1))\n",
    "        dice = self.calculate_dice(preds, masks.unsqueeze(1))\n",
    "        \n",
    "        # Log validation metrics\n",
    "        metrics = {\n",
    "            'val/loss': loss,\n",
    "            'val/iou': iou,\n",
    "            'val/dice': dice\n",
    "        }\n",
    "        self.log_dict(metrics, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        # Log validation images\n",
    "        if batch_idx == 0:\n",
    "            self._log_images(images, masks, outputs, 'val', self.current_epoch)\n",
    "            \n",
    "        return metrics\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.1,\n",
    "            patience=5,\n",
    "            verbose=True\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": scheduler,\n",
    "            \"monitor\": \"val/loss\"\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_iou(preds, targets):\n",
    "        intersection = torch.logical_and(preds, targets).sum()\n",
    "        union = torch.logical_or(preds, targets).sum()\n",
    "        iou = intersection / (union + 1e-6)\n",
    "        return iou\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_dice(preds, targets):\n",
    "        intersection = torch.logical_and(preds, targets).sum()\n",
    "        union = preds.sum() + targets.sum()\n",
    "        dice = 2 * intersection / (union + 1e-6)\n",
    "        return dice\n",
    "    \n",
    "    def _log_images(self, images, masks, outputs, stage, step):\n",
    "        n_images = min(4, images.shape[0])\n",
    "        predictions = torch.sigmoid(outputs) > 0.5\n",
    "        \n",
    "        for idx in range(n_images):\n",
    "            self.logger.experiment.add_image(\n",
    "                f'{stage}/image_{idx}',\n",
    "                images[idx],\n",
    "                step,\n",
    "                dataformats='CHW'\n",
    "            )\n",
    "            \n",
    "            self.logger.experiment.add_image(\n",
    "                f'{stage}/mask_{idx}',\n",
    "                masks[idx].float().unsqueeze(0),\n",
    "                step,\n",
    "                dataformats='CHW'\n",
    "            )\n",
    "            \n",
    "            self.logger.experiment.add_image(\n",
    "                f'{stage}/pred_{idx}',\n",
    "                predictions[idx].float(),\n",
    "                step,\n",
    "                dataformats='CHW'\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_training(model_config, data_module):\n",
    "    # Initialize TensorBoard logger\n",
    "    logger = TensorBoardLogger(\n",
    "        save_dir='lightning_logs',\n",
    "        name=f\"building_seg_{model_config['architecture']}_{model_config['backbone']}\",\n",
    "        default_hp_metric=False  # Disable automatic hp logging\n",
    "    )\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(\n",
    "            monitor='val/loss',\n",
    "            dirpath='checkpoints',\n",
    "            filename=f\"building_seg_{model_config['architecture']}\" + \n",
    "                     \"_{epoch:02d}_{val_loss:.3f}\",\n",
    "            save_top_k=3,\n",
    "            mode='min'\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor='val/loss',\n",
    "            patience=10,\n",
    "            mode='min'\n",
    "        ),\n",
    "        TQDMProgressBar(refresh_rate=20)\n",
    "    ]\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=model_config['epochs'],\n",
    "        accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "        devices=4,\n",
    "        callbacks=callbacks,\n",
    "        logger=logger,\n",
    "        precision=16,\n",
    "        log_every_n_steps=10\n",
    "    )\n",
    "    \n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Initialize data module\n",
    "data_module = BuildingSegmentationDataModule(\n",
    "    train_dir=TRAIN_DIR,\n",
    "    val_dir=VAL_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "# 3. Initialize model\n",
    "model = BuildingSegmentationModel(\n",
    "    architecture=MODEL_CONFIG['architecture'],\n",
    "    backbone=MODEL_CONFIG['backbone'],\n",
    "    learning_rate=MODEL_CONFIG['learning_rate']\n",
    ")\n",
    "\n",
    "# 4. Setup training\n",
    "trainer = setup_training(MODEL_CONFIG, data_module)\n",
    "\n",
    "# 5. Train the model\n",
    "trainer.fit(model, data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beam-lightning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
